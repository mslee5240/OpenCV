{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg8dV-3zsJcN"
   },
   "source": [
    "## **[CNN 기반의 숫자 이미지 분류 - MNIST 데이터셋 활용_by Pytorch]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pN1WTkg_r9m2"
   },
   "source": [
    "## 1.라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gNVa9_NsDq7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Tyl3eljrqfr"
   },
   "source": [
    "## 2.데이터 로딩 및 전처리\n",
    "- torchvision 라이브러리를 사용하여 MNIST 데이터셋을 다운로드\n",
    "- train=True로 설정하면 훈련용 데이터셋(60,000개의 이미지)을 불러옵니다. False로 설정하면 테스트용 데이터셋(10,000개의 이미지)을 불러옵니다.\n",
    "- transforms.ToTensor()는 이미지 데이터를 텐서로 변환합니다.\n",
    "    - 이미지의 픽셀 값이 [0, 255] 범위에서 [0.0, 1.0] 범위로 정규화됨\n",
    "    - MNIST 이미지는 원래 28x28 크기의 흑백 이미지로, 이를 [1, 28, 28] 크기의 3차원 텐서(채널, 높이, 너비)로 변환\n",
    "- 배치 크기 단위로 데이터 로더를 사용해 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKr_ckYw-QUV"
   },
   "outputs": [],
   "source": [
    "# 배치 사이즈 설정\n",
    "batch_size = 100\n",
    "# 데이터 저장 경로 설정\n",
    "root = './data'\n",
    "\n",
    "# MNIST 학습/테스트 데이터셋 다운로드 및 로드, 텐서로 변환\n",
    "mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "# 학습/테스 데이터 로더 설정 (데이터를 배치 크기만큼 나누고, 셔플하여 로드)\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# GPU 사용 가능 시 CUDA를 사용하고, 그렇지 않으면 CPU 사용\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZtnRvjGch_1"
   },
   "source": [
    "## 3.모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cndo9mDsczrx"
   },
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 첫 번째 Convolutional Layer: 입력 채널 1개, 출력 채널 32개, 커널 크기 3x3\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 두 번째 Convolutional Layer: 입력 채널 32개, 출력 채널 64개, 커널 크기 3x3\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layer: 7x7x64 -> 10개 클래스 출력\n",
    "        self.fc = nn.Linear(7*7*64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 모델 초기화\n",
    "model = CNN().to(device)\n",
    "\n",
    "# 모델 구조 출력\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8xzhrIqhl6_"
   },
   "source": [
    "- 모델 학습 과정을 위한 옵티마이저와 로스 함수 지정하기\n",
    "    - 옵티마이저는 SGD, Loss는 Cross Entropy Loss를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWl_Xu33TxYj"
   },
   "outputs": [],
   "source": [
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-B4VlhU7hyH5"
   },
   "source": [
    "## 4.모델학습하기\n",
    "- 구현 함수들을 이용해 학습 Loop를 구현해보세요.\n",
    "    - 손실 함수로 CrossEntropyLoss를 사용하며, Adam 옵티마이저를 사용해 모델 파라미터를 업데이트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mC1AW0Nrh5O_"
   },
   "outputs": [],
   "source": [
    "# 학습 에포크 수 설정\n",
    "training_epochs = 15\n",
    "\n",
    "# 학습 과정의 손실과 정확도를 추적하기 위한 리스트 초기화\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "# 학습 루프 시작\n",
    "for epoch in range(training_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    total_batch = len(train_loader)\n",
    "\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 배치 손실 및 정확도 계산\n",
    "        epoch_loss += loss.item()\n",
    "        _, argmax = torch.max(outputs, 1)\n",
    "        accuracy = (labels == argmax).float().mean()\n",
    "        epoch_accuracy += accuracy.item()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step[{}/{}, Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "                epoch + 1, training_epochs, i + 1, len(train_loader), loss.item(), accuracy.item() * 100\n",
    "            ))\n",
    "\n",
    "    epoch_loss /= total_batch\n",
    "    epoch_accuracy /= total_batch\n",
    "    loss_history.append(epoch_loss)\n",
    "    accuracy_history.append(epoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMC6E3ksQINT"
   },
   "source": [
    "## 5.학습 과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ft29AUC4QIk3"
   },
   "outputs": [],
   "source": [
    "# 학습 과정의 손실과 정확도를 그래프로 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(training_epochs), loss_history, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(training_epochs), accuracy_history, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6W3KLRemkfh"
   },
   "source": [
    "## 6.모델 평가하기\n",
    "- 학습이 끝난 후 테스트 데이터셋을 사용해 모델의 성능을 평가하고, 임의로 선택한 이미지에 대한 예측 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwD0yQkFTxmD"
   },
   "outputs": [],
   "source": [
    "# 모델을 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "# 평가 시 그래디언트 계산하지 않음\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (t_imgs, t_labels) in enumerate(test_loader):\n",
    "        t_imgs, t_labels = t_imgs.to(device), t_labels.to(device)\n",
    "\n",
    "        prediction = model(t_imgs)\n",
    "        _, argmax = torch.max(prediction, 1)\n",
    "        total += t_imgs.size(0)\n",
    "        correct += (t_labels == argmax).sum().item()\n",
    "\n",
    "    print(\"Test accuracy for {} images: {:.2f}%\".format(total, correct / total * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNf21ODhXtBO"
   },
   "source": [
    "## 7.모델 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoIPIxkyXqgJ"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터의 임의 샘플에 대해 예측 결과 시각화\n",
    "r = random.randint(0, len(mnist_test) - 1)\n",
    "t_imgs_data = mnist_test.test_data[r: r + 1].float().to(device)\n",
    "t_labels_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "print(\"Label: \", t_labels_data.item())\n",
    "single_prediction = model(t_imgs_data.unsqueeze(1))  # Add channel dimension\n",
    "print(\"Prediction: \", torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlpD_nBsvzrv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
