{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD0F6TFRN0Ri"
   },
   "source": [
    "## **손글씨 숫자 이미지 분류 - MNIST를 활용한 DNN 모델 만들기_by Tensorflow**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pnatXXrsW58"
   },
   "source": [
    "## 1.라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7504,
     "status": "ok",
     "timestamp": 1723468473244,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "Nv23kid7NvF3",
    "outputId": "e4deb62d-90b3-416e-8dc1-3ffbf36b9c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Omg51eZJPB5f"
   },
   "source": [
    "## 2.MNIST 데이터셋 가져오고 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGkx_RyRPUBQ"
   },
   "source": [
    "- Keras 에는 MNIST 데이터셋이 내장되어 있어서 tf.keras.datasets.mnist.load_data() 메소드로 로딩을 할 수 있습니다. Training set에 6만개, Test set에 1만개의 손글씨 숫자 데이터와 정답지 라벨 데이터가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1723468857741,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "4pUagOCxPMJd",
    "outputId": "16f6354a-a1cc-4929-c71c-a8cf949f4213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "shape of x_train: (60000, 28, 28)\n",
      "shape of y_train: (60000,)\n",
      "shape of x_test: (10000, 28, 28)\n",
      "shape of y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print('shape of x_train:', x_train.shape)\n",
    "print('shape of y_train:', y_train.shape)\n",
    "print('shape of x_test:', x_test.shape)\n",
    "print('shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfDmYCU1Pkl7"
   },
   "source": [
    "- Training set의 0번째 이미지 데이터 배열(28 by 28 array)과 정답지 라벨 ('5'), 그리고 matplotlib 으로 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1723468860580,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "LcUvEYIlPruu",
    "outputId": "794b0b19-0bd2-45d4-a3a2-a6485bb73e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1723468864189,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "1JSTzbloP5Gb",
    "outputId": "59630df8-1eed-4dfb-f947-aa23e7899c3d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-jj_ENO0bNf"
   },
   "source": [
    "## 3.데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTEbmQodQHzX"
   },
   "source": [
    "\n",
    "    - 형태 맞추기     \n",
    "Deep Neural Network 모델의 input으로 넣기 위해 (28 by 28) 2차원 배열 (2D array) 이미지를 (28 * 28 = 784) 의 옆으로 길게 펼친 데이터 형태로 변형(Reshape) 합니다(Flatten() 메소드를 사용해도 됨).\n",
    "    - 정규화하기      \n",
    "    신경망은 입력 데이터의 스케일에 민감하기 때문에, 이 값을 0과 1 사이의 범위로 조정하는 정규화 과정(0~255 사이의 값을 0~1 사이의 실수 값으로 변환) 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ-XX0qFQMX-"
   },
   "outputs": [],
   "source": [
    "# reshape and normalization\n",
    "x_train = x_train.reshape((60000, 28 * 28)) / 255.0\n",
    "x_test = x_test.reshape((10000, 28 * 28)) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwEWv3T4QV7q"
   },
   "source": [
    "## 4.모델 구현하기\n",
    "- Keras의 핵심 데이터 구조로 모델(Models)과 층(Layers)이 있습니다.\n",
    "    - 모델 구축 두가지 방법\n",
    "        - (a) 순차적으로 층을 쌓아가는 Sequential model 과,\n",
    "        - (b) 복잡한 구조의 모델을 만들 때 사용하는 Keras functional API\n",
    "- 이미지 데이터 분류는 CNN (Convolutional Neural Network) 을 사용하면 효과적이나 이 예제에서는 간단하게 Sequential model 을 사용하여 모델 구성합니다.\n",
    " - (1)에서 전처리한 Input 이미지 데이터를 받아서, 1개의 완전히 연결된 은닉층 (Fully Connected Hidden Layer) 을 쌓고,\n",
    " - 10개의 classes 별 확률을 반환하는 FC(Fully Connected) Output Layer 를 쌓아서 만든 DNN(Deep Neural Network) 모델을 만들어보겠습니다.(Functional API 는 PyTorch 와 유사함)  \n",
    " - add() 메소드를 사용하면 마치 레고 블록을 쌓듯이 차곡차곡 순서대로 원하는 층을 쌓아서 딥러닝 모델을 설계할 수 있습니다.\n",
    "\n",
    "- (Dense, CNN, RNN, Embedding 등 모두 가능). Dense() 층의 units 매개변수에는 층별 노드 개수를 지정해주며, 활성화 함수는 activation 매개변수에서 지정해줍니다. 은닉층에서는 'Relu' 활성화함수를, Output 층에는 10개 classes에 대한 확률을 반환하므로 'softmax' 활성화함수를 사용하였습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M63yGTXXt4hJ"
   },
   "source": [
    "### 1)모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rarR4EJpQv_f"
   },
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "# model = tf.keras.models.Sequential()\n",
    "# # Stacking layers\n",
    "# input_shape = (28*28,)\n",
    "# model.add(tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape))\n",
    "# model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28*28,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFWN-Ko2Q5m-"
   },
   "source": [
    "- 층을 쌓아서 만든 DNN (Deep Neural Network) 모델이 어떻게 생겼는지 summary() 함수로 출력해보고, tf.keras.utils.plot_model() 메소드로 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1723468870816,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "OIjEAm_RRAUJ",
    "outputId": "2f2f1f3b-07ca-420b-db35-9984338190a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOtB9e0hREEO"
   },
   "source": [
    "### 2)모델 컴파일 (Compiling the model)하기\n",
    "-  기계가 이 모델을 이해할 수 있고 학습 절차를 설정할 수 있도록 컴파일(Compile) 해줍니다. compile() 메소드에는 딥러닝 학습 시 사용하는 (a) 오차 역전파 경사하강법 시 최적화 알고리즘(optimizer), (b) 손실함수(loss function), 그리고 (c) 성과평가 지표(metrics) 를 설정해줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vio7-lW_RSMl"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
    "#     loss=keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-ufQNEPRgWQ"
   },
   "source": [
    " - input data의 다수 클래스에 대한 정답 레이블(ground-truth labels)을 바로 사용하여 손실함수를 계산할 때는 loss='sparse_categorical_crossentropy' 을 사용\n",
    " - One-hot encoding 형태로 정답 레이블이 되어있다면 loss='categorical_crossentropy' 를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKDAjkPdR6Jt"
   },
   "source": [
    "###  3)모델 학습 (Training the model)\n",
    "\n",
    "- 데이터 준비와 모델 구축, 그리고 모델 컴파일이 끝났으므로 이제 6만개의 훈련 데이터셋(Training set) 중에서 80% (4.8만개 데이터) 는 모델 학습(fitting)에, 20%(1.2만개 데이터)는 검증(validation)용으로 사용하여 DNN 모델을 학습해보겠습니다. (참고로, 1만개의 Test set은 모델 학습에서는 사용하지 않으며, 최종 모델에 대해서 제일 마지막에 모델 성능 평가를 위해서만 사용합니다.)\n",
    "- epochs = 5 는 전체 데이터를 5번 반복(iteration)해서 사용해서 학습한다는 의미입니다.\n",
    "- verbose = 1 은 모델 학습 진행상황 막대를 출력하라는 의미입니다. ('1' 이 default이므로 생략 가능)(0 = silent, 1 = progress bar, 2 = one line per epoch)\n",
    "- validation_split=0.2 는 검증용 데이터셋을 별도로 만들어놓지 않았을 때 학습용 데이터셋에서 지정한 비율(예: 20%) 만큼을 분할하여 (hyperparameter tuning을 위한) 검증용 데이터셋으로 이용하라는 의미입니다.\n",
    "- batch_size=32 는 한번에 데이터 32개씩 batch로 가져다가 학습에 사용하라는 의미입니다.\n",
    "- 학습이 진행될수록 (즉, epochs 이 증가할 수록) 검증용 데이터셋에 대한 손실 값(loss value)은 낮아지고 정확도(accuracy)는 올라가고 있네요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43391,
     "status": "ok",
     "timestamp": 1723468914203,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "nFElphylST3e",
    "outputId": "e42e0a8d-f9f5-4adf-ee22-10be715ecf29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7036 - loss: 1.1220 - val_accuracy: 0.8999 - val_loss: 0.3779\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.3834 - val_accuracy: 0.9150 - val_loss: 0.3075\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.3183 - val_accuracy: 0.9239 - val_loss: 0.2760\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2790 - val_accuracy: 0.9296 - val_loss: 0.2537\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.2587 - val_accuracy: 0.9338 - val_loss: 0.2368\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.2424 - val_accuracy: 0.9385 - val_loss: 0.2231\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.2237 - val_accuracy: 0.9423 - val_loss: 0.2115\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9391 - loss: 0.2159 - val_accuracy: 0.9460 - val_loss: 0.1991\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2005 - val_accuracy: 0.9489 - val_loss: 0.1896\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1900 - val_accuracy: 0.9513 - val_loss: 0.1818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c038c7b5ae0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HHVq7ZRSdcw"
   },
   "source": [
    "### 4)모델 평가 (Evaluating the model)\n",
    "= evaluate() 메소드를 사용하여 모델의 손실 값(Loss value) 과 컴파일 단계에서 추가로 설정해준 성능지표 값 (Metrics values) 을 Test set 에 대하여 평가할 수 있습니다. (다시 한번 강조하자면, Test set은 위의 (4)번 학습 단계에서 절대로 사용되어서는 안됩니다!)\n",
    "- Test set에 대한 cross entropy 손실값은 0.185, 정확도(accuracy)는 94.8% 가 나왔네요. (CNN 모델을 이용하고 hyperparameter tuning을 하면 99%까지 정확도를 올릴 수 있습니다.)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1723468915238,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "Vko90iZGS9el",
    "outputId": "0cb154c5-8c73-4886-bd6f-dd39e9e05b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 3ms/step - accuracy: 0.9497 - loss: 0.1804\n",
      "test_loss: 0.1804197132587433\n",
      "test_accuracy: 0.9496999979019165\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yK76ceIBTDi5"
   },
   "source": [
    "### 5)모델 예측하기 (Prediction for new data)\n",
    "위에서 학습한 DNN 모델을 사용해서 MNIST 이미지 데이터에 대해서 predict() 메소드를 사용하여 예측을 해보겠습니다. (별도의 새로운 데이터가 없으므로 test set 데이터를 사용함)굵은 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1723468916544,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "zgJK4_UITPW1",
    "outputId": "4c7682aa-9f8c-409d-e842-114f8e88409a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.5021130e-05, 3.8166014e-08, 3.6046369e-04, 2.5160944e-03,\n",
       "       3.9589960e-07, 4.7842412e-05, 1.3842259e-08, 9.9665952e-01,\n",
       "       2.5056717e-05, 3.4555409e-04], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "# returns an array of probability per classes\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1723468916544,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "GG6VJbIcTQBA",
    "outputId": "32ba60ce-65d6-4e23-e635-8459aab123f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# position of max probability\n",
    "np.argmax(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1723468916544,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "bFyEbMbdTaov",
    "outputId": "27c2b3da-b73b-4abf-af34-423e8f04e74c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1308,
     "status": "ok",
     "timestamp": 1723468917849,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "0wbwnx5Nzqjf",
    "outputId": "dd737b3d-5d83-4329-d904-117788082a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "model.predict() 결과 :  [4.5021130e-05 3.8166014e-08 3.6046369e-04 2.5160944e-03 3.9589960e-07\n",
      " 4.7842412e-05 1.3842259e-08 9.9665952e-01 2.5056717e-05 3.4555409e-04]\n",
      "model이 추론한 가장 가능성이 높은 결과 :  7\n",
      "실제 데이터의 라벨 :  7\n"
     ]
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test)  # model이 추론한 확률값.\n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=0  #1번째 x_test를 살펴보자.\n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1723469040566,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "-I7o2kwMzu-X",
    "outputId": "a6df8581-ac5f-4b5e-d78f-d171746931ab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[idx].reshape(28, 28), cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9WbY4VjTe28"
   },
   "source": [
    "### 6)모델 저장, 불러오기 (Saving and Loading the model)\n",
    "- 딥러닝 모델의 성과 평가 결과 기준치를 충족하여 현장 적용이 가능한 경우라면 모델의 요소와 학습된 가중치 정보를 파일 형태로 저장하고, 배포, 로딩해서 (재)활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR-ToWL8ToQZ"
   },
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "#model.save('mnist_dnn_model.h5')\n",
    "model.save('mnist_dnn_model.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KkAoW6vTtya"
   },
   "source": [
    "- 저장된 'mnist_dnn_model.h5' 모델/가중치 파일을 'new_model' 이름으로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1723469130575,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "45yJ6wsqTyKG",
    "outputId": "8eb6d501-2e29-432b-ecf2-39003b2ccddb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,542</span> (795.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m203,542\u001b[0m (795.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,772</span> (397.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m101,772\u001b[0m (397.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "#new_model = tf.keras.models.load_model('mnist_dnn_model.h5')\n",
    "new_model = tf.keras.models.load_model('mnist_dnn_model.keras')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "## **2. 의류 이미지 분류 - Fashion MNIST를 활용한 DNN 모델 만들기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "이 튜토리얼에서는 운동화나 셔츠 같은 옷 이미지를 분류하는 신경망 모델을 훈련합니다. 상세 내용을 모두 이해하지 못해도 괜찮습니다. 여기서는 완전한 텐서플로(TensorFlow) 프로그램을 빠르게 살펴 보겠습니다. 자세한 내용은 앞으로 배우면서 더 설명합니다.\n",
    "\n",
    "여기에서는 텐서플로 모델을 만들고 훈련할 수 있는 고수준 API인 [tf.keras](https://www.tensorflow.org/guide/keras)를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:03.209413Z",
     "iopub.status.busy": "2021-10-09T00:37:03.208893Z",
     "iopub.status.idle": "2021-10-09T00:37:04.729931Z",
     "shell.execute_reply": "2021-10-09T00:37:04.730297Z"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1723469136116,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "dzLKpmZICaWN",
    "outputId": "89339f75-5afb-4bf7-f720-39e638a455d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## 1) 패션 MNIST 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋을 사용하겠습니다. 이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 옷 품목을 나타냅니다:\n",
    "\n",
    "<table>\n",
    "  <tr><td>     <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\" alt=\"Fashion MNIST sprite\" width=\"600\">   </td></tr>\n",
    "  <tr><td align=\"center\">     <b>그림 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br>{nbsp}   </td></tr>\n",
    "</table>\n",
    "\n",
    "패션 MNIST는 컴퓨터 비전 분야의 \"Hello, World\" 프로그램격인 고전 [MNIST](http://yann.lecun.com/exdb/mnist/) 데이터셋을 대신해서 자주 사용됩니다. MNIST 데이터셋은 손글씨 숫자(0, 1, 2 등)의 이미지로 이루어져 있습니다. 여기서 사용하려는 옷 이미지와 동일한 포맷입니다.\n",
    "\n",
    "패션 MNIST는 일반적인 MNIST 보다 조금 더 어려운 문제이고 다양한 예제를 만들기 위해 선택했습니다. 두 데이터셋은 비교적 작기 때문에 알고리즘의 작동 여부를 확인하기 위해 사용되곤 합니다. 코드를 테스트하고 디버깅하는 용도로 좋습니다.\n",
    "\n",
    "여기에서 60,000개의 이미지를 사용하여 네트워크를 훈련하고 10,000개의 이미지를 사용하여 네트워크에서 이미지 분류를 학습한 정도를 평가합니다. TensorFlow에서 직접 Fashion MNIST에 액세스할 수 있습니다. TensorFlow에서 직접 [Fashion MNIST 데이터](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data)를 가져오고 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:04.734895Z",
     "iopub.status.busy": "2021-10-09T00:37:04.734362Z",
     "iopub.status.idle": "2021-10-09T00:37:05.637249Z",
     "shell.execute_reply": "2021-10-09T00:37:05.636740Z"
    },
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "...     # ... 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9FDsUlxCaWW"
   },
   "source": [
    "load_data() 함수를 호출하면 네 개의 넘파이(NumPy) 배열이 반환됩니다:\n",
    "\n",
    "- `train_images`와 `train_labels` 배열은 모델 학습에 사용되는 *훈련 세트*입니다.\n",
    "- `test_images`와 `test_labels` 배열은 모델 테스트에 사용되는 *테스트 세트*입니다.\n",
    "\n",
    "이미지는 28x28 크기의 넘파이 배열이고 픽셀 값은 0과 255 사이입니다. *레이블*(label)은 0에서 9까지의 정수 배열입니다. 이 값은 이미지에 있는 옷의 *클래스*(class)를 나타냅니다:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>레이블</th>\n",
    "    <th>클래스</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "각 이미지는 하나의 레이블에 매핑되어 있습니다. 데이터셋에 *클래스 이름*이 들어있지 않기 때문에 나중에 이미지를 출력할 때 사용하기 위해 별도의 변수를 만들어 저장합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.641741Z",
     "iopub.status.busy": "2021-10-09T00:37:05.641192Z",
     "iopub.status.idle": "2021-10-09T00:37:05.643058Z",
     "shell.execute_reply": "2021-10-09T00:37:05.642671Z"
    },
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## 2) 데이터 탐색\n",
    "\n",
    "모델을 훈련하기 전에 데이터셋 구조를 살펴보죠. 다음 코드는 훈련 세트에 60,000개의 이미지가 있다는 것을 보여줍니다. 각 이미지는 28x28 픽셀로 표현됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.648800Z",
     "iopub.status.busy": "2021-10-09T00:37:05.648200Z",
     "iopub.status.idle": "2021-10-09T00:37:05.650659Z",
     "shell.execute_reply": "2021-10-09T00:37:05.651008Z"
    },
    "id": "zW5k_xz1CaWX"
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIAcvQqMCaWf"
   },
   "source": [
    "비슷하게 훈련 세트에는 60,000개의 레이블이 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.655028Z",
     "iopub.status.busy": "2021-10-09T00:37:05.654469Z",
     "iopub.status.idle": "2021-10-09T00:37:05.656993Z",
     "shell.execute_reply": "2021-10-09T00:37:05.657313Z"
    },
    "id": "TRFYHB2mCaWb"
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSlYxFuRCaWk"
   },
   "source": [
    "각 레이블은 0과 9사이의 정수입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.661703Z",
     "iopub.status.busy": "2021-10-09T00:37:05.661122Z",
     "iopub.status.idle": "2021-10-09T00:37:05.664363Z",
     "shell.execute_reply": "2021-10-09T00:37:05.663970Z"
    },
    "id": "XKnCTHz4CaWg"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMPI88iZpO2T"
   },
   "source": [
    "테스트 세트에는 10,000개의 이미지가 있습니다. 이 이미지도 28x28 픽셀로 표현됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.668323Z",
     "iopub.status.busy": "2021-10-09T00:37:05.667776Z",
     "iopub.status.idle": "2021-10-09T00:37:05.670735Z",
     "shell.execute_reply": "2021-10-09T00:37:05.671052Z"
    },
    "id": "2KFnYlcwCaWl"
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd0A0Iu0CaWq"
   },
   "source": [
    "테스트 세트는 10,000개의 이미지에 대한 레이블을 가지고 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.675035Z",
     "iopub.status.busy": "2021-10-09T00:37:05.674468Z",
     "iopub.status.idle": "2021-10-09T00:37:05.677824Z",
     "shell.execute_reply": "2021-10-09T00:37:05.677397Z"
    },
    "id": "iJmPr5-ACaWn"
   },
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## 3) 데이터 전처리\n",
    "\n",
    "네트워크를 훈련하기 전에 데이터를 전처리해야 합니다. 훈련 세트에 있는 첫 번째 이미지를 보면 픽셀 값의 범위가 0~255 사이라는 것을 알 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.720032Z",
     "iopub.status.busy": "2021-10-09T00:37:05.693493Z",
     "iopub.status.idle": "2021-10-09T00:37:05.850523Z",
     "shell.execute_reply": "2021-10-09T00:37:05.850130Z"
    },
    "id": "m4VEw8Ud9Quh"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz7l27Lz9S1P"
   },
   "source": [
    "신경망 모델에 주입하기 전에 이 값의 범위를 0~1 사이로 조정하겠습니다. 이렇게 하려면 255로 나누어야 합니다. *훈련 세트*와 *테스트 세트*를 동일한 방식으로 전처리하는 것이 중요합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.854160Z",
     "iopub.status.busy": "2021-10-09T00:37:05.853630Z",
     "iopub.status.idle": "2021-10-09T00:37:05.998526Z",
     "shell.execute_reply": "2021-10-09T00:37:05.998008Z"
    },
    "id": "bW5WzIPlCaWv"
   },
   "outputs": [],
   "source": [
    "train_images = ...     # ... 코드 입력\n",
    "\n",
    "test_images = ...     # ... 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "*훈련 세트*에서 처음 25개 이미지와 그 아래 클래스 이름을 출력해 보죠. 데이터 포맷이 올바른지 확인하고 네트워크 구성과 훈련할 준비를 마칩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:06.077668Z",
     "iopub.status.busy": "2021-10-09T00:37:06.051526Z",
     "iopub.status.idle": "2021-10-09T00:37:06.852985Z",
     "shell.execute_reply": "2021-10-09T00:37:06.852546Z"
    },
    "id": "oZTImqg_CaW1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## 4) 모델 구성\n",
    "\n",
    "신경망 모델을 만들려면 모델의 층을 구성한 다음 모델을 컴파일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxg1XGm0eOBy"
   },
   "source": [
    "### 4-1)층 설정\n",
    "\n",
    "신경망의 기본 빌딩 블록은 [*레이어*](https://www.tensorflow.org/api_docs/python/tf/keras/layers) 입니다. 레이어는 레이어에 공급된 데이터로부터 표현을 추출합니다. 이러한 표현은 당면한 문제에 의미가 있어야 합니다.\n",
    "\n",
    "대부분 딥러닝은 간단한 층을 연결하여 구성됩니다. `tf.keras.layers.Dense`와 같은 층들의 가중치(parameter)는 훈련하는 동안 학습됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:06.858821Z",
     "iopub.status.busy": "2021-10-09T00:37:06.857327Z",
     "iopub.status.idle": "2021-10-09T00:37:08.396243Z",
     "shell.execute_reply": "2021-10-09T00:37:08.396719Z"
    },
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "# 1개의 은닉층 - 노드 128 개 인 모델을 구성하세요\n",
    "model =  ...    # ... 코드 입력\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "이 네트워크의 첫 번째 층인 `tf.keras.layers.Flatten`은 2차원 배열(28 x 28 픽셀)의 이미지 포맷을 28 * 28 = 784 픽셀의 1차원 배열로 변환합니다. 이 층은 이미지에 있는 픽셀의 행을 펼쳐서 일렬로 늘립니다. 이 층에는 학습되는 가중치가 없고 데이터를 변환하기만 합니다.\n",
    "\n",
    "픽셀을 펼친 후에는 두 개의 `tf.keras.layers.Dense` 층이 연속되어 연결됩니다. 이 층을 밀집 연결(densely-connected) 또는 완전 연결(fully-connected) 층이라고 부릅니다. 첫 번째 `Dense` 층은 128개의 노드(또는 뉴런)를 가집니다. 두 번째 (마지막) 층은 10개의 노드의 *소프트맥스*(softmax) 층입니다. 이 층은 10개의 확률을 반환하고 반환된 값의 전체 합은 1입니다. 각 노드는 현재 이미지가 10개 클래스 중 하나에 속할 확률을 출력합니다.\n",
    "\n",
    "### 4-2)모델 컴파일\n",
    "\n",
    "모델을 훈련할 준비가 되기 전에 몇 가지 설정이 더 필요합니다. 다음은 모델의 [*컴파일*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) 단계에서 추가됩니다.\n",
    "\n",
    "- [*손실 함수*](https://www.tensorflow.org/api_docs/python/tf/keras/losses) - 훈련 중 모델이 얼마나 정확한지 측정합니다. 모델을 올바른 방향으로 \"조정\"하려면 이 함수를 최소화해야 합니다.\n",
    "- [*옵티마이저*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) - 모델이 인식하는 데이터와 해당 손실 함수를 기반으로 모델이 업데이트되는 방식입니다.\n",
    "- [*메트릭*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) — 훈련 및 테스트 단계를 모니터링하는 데 사용됩니다. 다음 예에서는 올바르게 분류된 이미지의 비율인 *정확도*를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:08.405187Z",
     "iopub.status.busy": "2021-10-09T00:37:08.404649Z",
     "iopub.status.idle": "2021-10-09T00:37:08.412602Z",
     "shell.execute_reply": "2021-10-09T00:37:08.412174Z"
    },
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "# 모델 컴파일하기 : 손실함수 - 'sparse_categorical_crossentropy', 옵티마이저 : 'adam' , metricsc : 'accuracy'\n",
    "\n",
    "...    # ... 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## 5) 모델 훈련\n",
    "\n",
    "신경망 모델을 훈련하려면 다음 단계가 필요합니다.\n",
    "\n",
    "1. 훈련 데이터를 모델에 주입합니다-이 예에서는 `train_images`와 `train_labels` 배열입니다.\n",
    "2. 모델이 이미지와 레이블을 매핑하는 방법을 배웁니다.\n",
    "3. 테스트 세트에 대한 모델의 예측을 만듭니다-이 예에서는 `test_images` 배열입니다. 이 예측이 `test_labels` 배열의 레이블과 맞는지 확인합니다.\n",
    "4. 예측이 `test_labels` 배열의 레이블과 일치하는지 확인합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4P4zIV7E28Z"
   },
   "source": [
    "- 모델 학습\n",
    "\n",
    "훈련을 시작하려면 [`model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) 메서드를 호출합니다. 모델을 훈련 데이터에 \"맞추기(fit)\" 때문에 이렇게 불립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:08.416634Z",
     "iopub.status.busy": "2021-10-09T00:37:08.416057Z",
     "iopub.status.idle": "2021-10-09T00:37:35.643885Z",
     "shell.execute_reply": "2021-10-09T00:37:35.644240Z"
    },
    "id": "xvwvpA64CaW_"
   },
   "outputs": [],
   "source": [
    "# 모델 학습하기  - epochs = 10\n",
    "history = ...     # ... 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rn3dfNvxmbu5"
   },
   "source": [
    "## 6) 모델 훈련 후 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0u35pqiHmb8c"
   },
   "outputs": [],
   "source": [
    "# 모델 학습과정 그래프로 나타내기\n",
    "\n",
    "...     # ... 코드 입력\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ZVOhugCaXA"
   },
   "source": [
    "모델이 훈련되면서 손실과 정확도 지표가 출력됩니다. 이 모델은 훈련 세트에서 약 0.88(88%) 정도의 정확도를 달성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCpr6DGyE28h"
   },
   "source": [
    "## 7) 모델 평가\n",
    "\n",
    "모델이 테스트 데이터세트에서 작동하는 방식을 비교합니다. - evaluate() 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:35.648923Z",
     "iopub.status.busy": "2021-10-09T00:37:35.648296Z",
     "iopub.status.idle": "2021-10-09T00:37:36.162471Z",
     "shell.execute_reply": "2021-10-09T00:37:36.162831Z"
    },
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = ...     # ... 코드 입력\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWfgsmVXCaXG"
   },
   "source": [
    "테스트 세트의 정확도가 훈련 세트의 정확도보다 조금 낮습니다. 훈련 세트의 정확도와 테스트 세트의 정확도 사이의 차이는 *과대적합*(overfitting) 때문입니다. 과대적합은 머신러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 현상을 말합니다.\n",
    "\n",
    "- [과대적합 시연](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting)\n",
    "- [과대적합을 방지하기 위한 전략](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PyD1SYE28q"
   },
   "source": [
    "## 8) 예측하기\n",
    "\n",
    "훈련된 모델을 사용하여 일부 이미지에 대한 예측을 수행할 수 있습니다. 모델의 선형 출력, [로짓](https://developers.google.com/machine-learning/glossary#logits). 소프트맥스 레이어를 연결하여 로짓을 해석하기 쉬운 확률로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.167730Z",
     "iopub.status.busy": "2021-10-09T00:37:36.167212Z",
     "iopub.status.idle": "2021-10-09T00:37:36.180366Z",
     "shell.execute_reply": "2021-10-09T00:37:36.179971Z"
    },
    "id": "DnfNA0CrQLSD"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model,\n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.183891Z",
     "iopub.status.busy": "2021-10-09T00:37:36.183346Z",
     "iopub.status.idle": "2021-10-09T00:37:36.517176Z",
     "shell.execute_reply": "2021-10-09T00:37:36.517584Z"
    },
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9Kk1voUCaXJ"
   },
   "source": [
    "여기서는 테스트 세트에 있는 각 이미지의 레이블을 예측했습니다. 첫 번째 예측을 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.522707Z",
     "iopub.status.busy": "2021-10-09T00:37:36.521976Z",
     "iopub.status.idle": "2021-10-09T00:37:36.524636Z",
     "shell.execute_reply": "2021-10-09T00:37:36.524984Z"
    },
    "id": "3DmJEUinCaXK"
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hw1hgeSCaXN"
   },
   "source": [
    "이 예측은 10개의 숫자 배열로 나타납니다. 이 값은 10개의 옷 품목에 상응하는 모델의 신뢰도(confidence)를 나타냅니다. 가장 높은 신뢰도를 가진 레이블을 찾아보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.529353Z",
     "iopub.status.busy": "2021-10-09T00:37:36.528635Z",
     "iopub.status.idle": "2021-10-09T00:37:36.531474Z",
     "shell.execute_reply": "2021-10-09T00:37:36.530989Z"
    },
    "id": "qsqenuPnCaXO"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E51yS7iCCaXO"
   },
   "source": [
    "모델은 이 이미지가 앵클 부츠(`class_name[9]`)라고 가장 확신하고 있습니다. 이 값이 맞는지 테스트 레이블을 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.535822Z",
     "iopub.status.busy": "2021-10-09T00:37:36.535087Z",
     "iopub.status.idle": "2021-10-09T00:37:36.537594Z",
     "shell.execute_reply": "2021-10-09T00:37:36.537953Z"
    },
    "id": "Sd7Pgsu6CaXP"
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygh2yYC972ne"
   },
   "source": [
    "10개 클래스에 대한 예측을 모두 그래프로 표현해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.544429Z",
     "iopub.status.busy": "2021-10-09T00:37:36.543805Z",
     "iopub.status.idle": "2021-10-09T00:37:36.546023Z",
     "shell.execute_reply": "2021-10-09T00:37:36.545602Z"
    },
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh9yABaME29S"
   },
   "source": [
    "## 9) 예측 확인\n",
    "\n",
    "훈련된 모델을 사용하여 일부 이미지에 대한 예측을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Ov9OFDMmOD"
   },
   "source": [
    "0번째 원소의 이미지, 예측, 신뢰도 점수 배열을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.566345Z",
     "iopub.status.busy": "2021-10-09T00:37:36.565751Z",
     "iopub.status.idle": "2021-10-09T00:37:36.658377Z",
     "shell.execute_reply": "2021-10-09T00:37:36.657973Z"
    },
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.678220Z",
     "iopub.status.busy": "2021-10-09T00:37:36.673370Z",
     "iopub.status.idle": "2021-10-09T00:37:36.768534Z",
     "shell.execute_reply": "2021-10-09T00:37:36.768941Z"
    },
    "id": "Ko-uzOufSCSe"
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "몇 개의 이미지의 예측을 출력해 보죠. 올바르게 예측된 레이블은 파란색이고 잘못 예측된 레이블은 빨강색입니다. 숫자는 예측 레이블의 신뢰도 퍼센트(100점 만점)입니다. 신뢰도 점수가 높을 때도 잘못 예측할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.818460Z",
     "iopub.status.busy": "2021-10-09T00:37:36.803865Z",
     "iopub.status.idle": "2021-10-09T00:37:38.507593Z",
     "shell.execute_reply": "2021-10-09T00:37:38.507977Z"
    },
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R32zteKHCaXT"
   },
   "source": [
    "## 10) 훈련된 모델 사용하기\n",
    "\n",
    "마지막으로 훈련된 모델을 사용하여 한 이미지에 대한 예측을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.512157Z",
     "iopub.status.busy": "2021-10-09T00:37:38.511582Z",
     "iopub.status.idle": "2021-10-09T00:37:38.513998Z",
     "shell.execute_reply": "2021-10-09T00:37:38.513554Z"
    },
    "id": "yRJ7JU7JCaXT"
   },
   "outputs": [],
   "source": [
    "# Grab an image from the test dataset.\n",
    "img = test_images[1]\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz3bVp21CaXV"
   },
   "source": [
    "`tf.keras` 모델은 한 번에 샘플의 묶음 또는 *배치*(batch)로 예측을 만드는데 최적화되어 있습니다. 하나의 이미지를 사용할 때에도 2차원 배열로 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.517877Z",
     "iopub.status.busy": "2021-10-09T00:37:38.517310Z",
     "iopub.status.idle": "2021-10-09T00:37:38.519150Z",
     "shell.execute_reply": "2021-10-09T00:37:38.519501Z"
    },
    "id": "lDFh5yF_CaXW"
   },
   "outputs": [],
   "source": [
    "# Add the image to a batch where it's the only member.\n",
    "img = (np.expand_dims(img,0))\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ5wLTkcCaXY"
   },
   "source": [
    "이제 이 이미지의 예측을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.523771Z",
     "iopub.status.busy": "2021-10-09T00:37:38.523232Z",
     "iopub.status.idle": "2021-10-09T00:37:38.556846Z",
     "shell.execute_reply": "2021-10-09T00:37:38.556341Z"
    },
    "id": "o_rzNSdrCaXY"
   },
   "outputs": [],
   "source": [
    "predictions_single = probability_model.predict(img)\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.597375Z",
     "iopub.status.busy": "2021-10-09T00:37:38.596804Z",
     "iopub.status.idle": "2021-10-09T00:37:38.650107Z",
     "shell.execute_reply": "2021-10-09T00:37:38.649667Z"
    },
    "id": "6Ai-cpLjO-3A"
   },
   "outputs": [],
   "source": [
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU1Y2OAMCaXb"
   },
   "source": [
    "`tf.keras.Model.predict`는 데이터 배치의 각 이미지에 대해 하나의 목록씩 목록의 목록을 반환합니다. 배치에서 (유일한) 이미지에 대한 예측을 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.654503Z",
     "iopub.status.busy": "2021-10-09T00:37:38.653890Z",
     "iopub.status.idle": "2021-10-09T00:37:38.656449Z",
     "shell.execute_reply": "2021-10-09T00:37:38.656801Z"
    },
    "id": "2tRmdq_8CaXb"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "예상과 같이 모델이 레이블을 예측합니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mygpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
