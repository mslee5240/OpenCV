{"cells":[{"cell_type":"markdown","source":["## **손글씨 숫자 이미지 분류 - by Pytorch**\n","- https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html"],"metadata":{"id":"Zg8dV-3zsJcN"}},{"cell_type":"markdown","source":["## [ 단층신경망 - 선형회귀 사용]\n","\n","`torch.nn` : **Neural Network(신경망)**를 구성하고 동작하게 하는 데 필요한 다양한 구성 요소와 기능들을 제공하는 **모듈**로 신경망을 구축하는 데 필요한 기본적인 **레이어, 활성화 함수, 손실 함수** 등을 포함하고 있습니다.\n","\n","1. **레이어 (Layers)**:\n","   - `nn.Linear`: 선형 변환을 수행하는 완전 연결층 (Fully Connected Layer).\n","   - `nn.Conv2d`: 2D 합성곱(Convolution)을 수행하는 합성곱층.\n","   - `nn.RNN`, `nn.LSTM`, `nn.GRU`: 순환 신경망(RNN) 레이어들.\n","\n","2. **활성화 함수 (Activation Functions)**:\n","   - `nn.ReLU`: ReLU (Rectified Linear Unit) 활성화 함수.\n","   - `nn.Sigmoid`: 시그모이드 활성화 함수.\n","   - `nn.Softmax`: 소프트맥스 활성화 함수.\n","\n","3. **손실 함수 (Loss Functions)**:\n","   - `nn.CrossEntropyLoss`: 교차 엔트로피 손실 함수.\n","   - `nn.MSELoss`: 평균 제곱 오차 손실 함수.\n","\n","4. **컨테이너 (Containers)**:\n","   - `nn.Sequential`: 여러 레이어를 순차적으로 쌓아 하나의 모델로 정의.\n","   - `nn.Module`: 모든 신경망 모듈의 기본 클래스. 사용자 정의 신경망을 만들 때 상속받아 사용."],"metadata":{"id":"Iy6g6UMu6OQT"}},{"cell_type":"markdown","source":["## 1.라이브러리 가져오기"],"metadata":{"id":"pN1WTkg_r9m2"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import random\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"4gNVa9_NsDq7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.데이터 로딩 및 전처리\n","- torchvision 라이브러리를 사용하여 MNIST 데이터셋을 다운로드\n","- train=True로 설정하면 훈련용 데이터셋(60,000개의 이미지)을 불러옵니다. False로 설정하면 테스트용 데이터셋(10,000개의 이미지)을 불러옵니다.\n","- transforms.ToTensor()는 이미지 데이터를 텐서로 변환합니다.\n","    - 이미지의 픽셀 값이 [0, 255] 범위에서 [0.0, 1.0] 범위로 정규화됨\n","    - MNIST 이미지는 원래 28x28 크기의 흑백 이미지로, 이를 [1, 28, 28] 크기의 3차원 텐서(채널, 높이, 너비)로 변환\n","- 배치 크기 단위로 데이터 로더를 사용해 데이터를 불러옵니다."],"metadata":{"id":"4Tyl3eljrqfr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKr_ckYw-QUV"},"outputs":[],"source":["# 배치 사이즈 설정\n","batch_size = 100\n","# 데이터 저장 경로 설정\n","root = './data'\n","\n","# MNIST 학습/테스트 데이터셋 다운로드 및 로드, 텐서로 변환\n","mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n","mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n","\n","# 학습/테스 데이터 로더 설정 (데이터를 배치 크기만큼 나누고, 셔플하여 로드)\n","train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, drop_last=True)\n","\n","# GPU 사용 가능 시 CUDA를 사용하고, 그렇지 않으면 CPU 사용\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"device\", device)"]},{"cell_type":"markdown","metadata":{"id":"DZtnRvjGch_1"},"source":["## 3.모델 정의하기\n","\n","- 간단한 선형 모델(Linear)을 정의하여 28x28 이미지를 10개의 클래스(숫자 0~9)로 분류하도록 합니다.\n","- MNIST 입력의 크기는 28x28입니다.\n","- 여기서 구현하는 linear 모델은 입력이 1차원이기 때문에 입력 차원을 맞춰야합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cndo9mDsczrx"},"outputs":[],"source":["# 단순 선형 모델 정의 (28*28 크기의 이미지를 10개의 클래스로 분류)\n","linear = torch.nn.Linear(28*28, 10, bias=True).to(device)\n","# 가중치를 정규분포로 초기화 (in-place)\n","torch.nn.init.normal(linear.weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsUFAimHgL7v"},"outputs":[],"source":["print(train_loader)"]},{"cell_type":"markdown","metadata":{"id":"X8xzhrIqhl6_"},"source":["- 모델 학습 과정을 위한 옵티마이저와 로스 함수 지정하기\n","    - 옵티마이저는 SGD, Loss는 Cross Entropy Loss를 사용합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWl_Xu33TxYj"},"outputs":[],"source":["# 손실 함수로 교차 엔트로피 사용\n","criterion = torch.nn.CrossEntropyLoss().to(device)\n","# 옵티마이저로 SGD 사용, 학습률 0.1\n","optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"]},{"cell_type":"markdown","metadata":{"id":"-B4VlhU7hyH5"},"source":["## 4.모델학습하기\n","- 구현 함수들을 이용해 학습 Loop를 구현해보세요.\n","    - 손실 함수로 CrossEntropyLoss를 사용하며, SGD 옵티마이저를 사용해 모델 파라미터를 업데이트합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mC1AW0Nrh5O_"},"outputs":[],"source":["# 학습 에포크 수 설정\n","training_epochs = 15\n","\n","# 학습 과정의 손실과 정확도를 추적하기 위한 리스트 초기화\n","loss_history = []\n","accuracy_history = []\n","\n","# 학습 루프 시작\n","for epoch in range(training_epochs):\n","    avg_cost = 0\n","    total_batch = len(train_loader)\n","\n","    epoch_loss = 0\n","    epoch_accuracy = 0\n","\n","    # 미니 배치 단위로 학습\n","    for i, (imgs, labels) in enumerate(train_loader):\n","        # 입력 이미지와 레이블을 GPU 또는 CPU로 이동\n","        imgs, labels = imgs.to(device), labels.to(device)\n","        # 이미지를 1차원 벡터로 변환 (28x28 -> 784)\n","        imgs = imgs.view(-1, 28 * 28)\n","\n","        # 모델을 사용하여 예측값 계산\n","        outputs = linear(imgs)\n","        # 손실 계산\n","        loss = criterion(outputs, labels)\n","\n","        # 옵티마이저의 그래디언트 초기화\n","        optimizer.zero_grad()\n","        # 손실을 역전파하여 그래디언트 계산\n","        loss.backward()\n","        # 옵티마이저로 가중치 업데이트\n","        optimizer.step()\n","\n","        # 배치 손실 및 정확도 계산\n","        epoch_loss += loss.item()\n","        # 모델 예측 -  outputs : [0.1, 0.2, 0.05, 0.9, 0.4, 0.3, 0.2, 0.1, 0.1, 0.1]이라면, torch.max(outputs, 1)은 (0.9, 3)을 반환\n","        _, argmax = torch.max(outputs, 1)\n","        accuracy = (labels == argmax).float().mean()   # 부동 소수점 텐서로 변환 : True는 1.0, False는 0.0\n","        epoch_accuracy += accuracy.item()\n","\n","        # 100번의 반복마다 손실과 정확도 출력\n","        if (i + 1) % 100 == 0:\n","            print('Epoch [{}/{}], Step[{}/{}, Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n","                epoch + 1, training_epochs, i + 1, len(train_loader), loss.item(), accuracy.item() * 100\n","            ))\n","\n","    # 에포크마다 평균 손실과 정확도 기록\n","    epoch_loss /= total_batch\n","    epoch_accuracy /= total_batch\n","    loss_history.append(epoch_loss)\n","    accuracy_history.append(epoch_accuracy)"]},{"cell_type":"markdown","source":["## 5.학습 과정 시각화"],"metadata":{"id":"IMC6E3ksQINT"}},{"cell_type":"code","source":["# 학습 과정의 손실과 정확도를 그래프로 시각화\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(range(training_epochs), loss_history, label='Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(range(training_epochs), accuracy_history, label='Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Training Accuracy')\n","\n","plt.show()"],"metadata":{"id":"ft29AUC4QIk3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X6W3KLRemkfh"},"source":["## 6.모델 평가하기\n","- 학습이 끝난 후 테스트 데이터셋을 사용해 모델의 성능을 평가하고, 임의로 선택한 이미지에 대한 예측 결과를 출력합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TwD0yQkFTxmD"},"outputs":[],"source":["# 모델을 평가 모드로 전환\n","linear.eval()\n","\n","# 평가 시 그래디언트 계산하지 않음\n","with torch.no_grad():             # torch.no_grad() : gradient를 계산안함\n","    correct = 0    # 모델이 올바르게 예측한 이미지의 수를 누적하기 위한 변수\n","    total = 0      # 테스트한 전체 이미지의 수를 누적하기 위한 변수\n","\n","    # 테스트 데이터셋을 사용하여 정확도 평가\n","    for i, (t_imgs, t_labels) in enumerate(test_loader):\n","        t_imgs, t_labels = t_imgs.to(device), t_labels.to(device)\n","        # 28x28 크기의 2차원 이미지를 (batch_size, 784) 크기의 1차원 벡터로 변환\n","        t_imgs = t_imgs.view(-1, 28 * 28)\n","\n","        # 테스트 이미지에 대한 예측값 계산\n","        prediction = linear(t_imgs)\n","\n","        # 예측된 레이블과 실제 레이블 비교하여 정확도 계산\n","        _, argmax = torch.max(prediction, 1)\n","        total += t_imgs.size(0)    # t_imgs.size(0) : 배치 사이즈\n","        correct += (t_labels == argmax).sum().item()  # .sum():맞은 예측의 수 계산,.item()은 그 값을 파이썬의 숫자로 변환 - tensor(5.0)인 경우, 5.0이라는 숫자를 추출하여 파이썬의 float 타입으로 변환\n","\n","    # 전체 테스트 데이터에 대한 정확도 출력\n","    print(\"Test accuracy for {} images: {:.2f}%\".format(total, correct / total*100))"]},{"cell_type":"markdown","metadata":{"id":"YNf21ODhXtBO"},"source":["## 7.모델 예측하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SoIPIxkyXqgJ"},"outputs":[],"source":["# 테스트 데이터의 임의 샘플에 대해 예측 결과 시각화\n","r = random.randint(0, len(mnist_test) - 1)  # r:테스트 데이터에서 무작위로 선택한 이미지의 인덱스번호\n","\n","t_imgs_data = mnist_test.test_data[r: r + 1].view(-1, 28 * 28).float().to(device)\n","t_labels_data = mnist_test.test_labels[r:r + 1].to(device)\n","\n","print(\"Label: \", t_labels_data.item())  # 이블 값을 텐서에서 추출하여 파이썬의 정수로 변환\n","\n","# 모델 예측 수행\n","single_prediction = linear(t_imgs_data)\n","print(\"Prediction: \", torch.argmax(single_prediction, 1).item())\n","\n","plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap=\"Greys\", interpolation=\"nearest\")   # interpolation=\"nearest\" : 이미지를 확대할 때 픽셀의 경계가 뚜렷하게 유지되도록 하는 옵션\n","plt.show()"]},{"cell_type":"markdown","source":["## [ 심층신경망, DNN ]"],"metadata":{"id":"RIAwGMm76WC8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TlpD_nBsvzrv"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets as dset\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","\n","# 배치 사이즈 설정\n","batch_size = 100\n","\n","# 데이터 저장 경로 설정\n","root = './data'\n","\n","# MNIST 학습/테스트 데이터셋 다운로드 및 로드, 텐서로 변환\n","mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n","mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n","\n","# 학습/테스트 데이터 로더 설정 (데이터를 배치 크기만큼 나누고, 셔플하여 로드)\n","train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","# GPU 사용 가능 시 CUDA를 사용하고, 그렇지 않으면 CPU 사용\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"device:\", device)\n","\n","# 모델 정의 (히든 레이어 추가)\n","class SimpleDNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleDNN, self).__init__()\n","        self.fc1 = nn.Linear(28*28, 128)  # 첫 번째 히든 레이어 (128 유닛)\n","        self.relu = nn.ReLU()             # ReLU 활성화 함수\n","        self.fc2 = nn.Linear(128, 10)     # 출력 레이어 (10 유닛, 클래스 수)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)   # 입력을 첫 번째 히든 레이어에 전달\n","        x = self.relu(x)  # ReLU 활성화 함수 적용\n","        x = self.fc2(x)   # 히든 레이어 출력을 출력 레이어에 전달\n","        return x\n","\n","# 모델 초기화\n","model = SimpleDNN().to(device)\n","\n","# 손실 함수, 옵티마이저 정의\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# 학습 에포크 수 설정\n","training_epochs = 15\n","\n","# 학습 과정의 손실과 정확도를 추적하기 위한 리스트 초기화\n","loss_history = []\n","accuracy_history = []\n","\n","# 학습 루프 시작\n","for epoch in range(training_epochs):\n","    epoch_loss = 0\n","    epoch_accuracy = 0\n","\n","    # 미니 배치 단위로 학습\n","    for i, (imgs, labels) in enumerate(train_loader):\n","        # 입력 이미지와 레이블을 GPU 또는 CPU로 이동\n","        imgs, labels = imgs.to(device), labels.to(device)\n","        # 이미지를 1차원 벡터로 변환 (28x28 -> 784)\n","        imgs = imgs.view(-1, 28 * 28)\n","\n","        # 모델을 사용하여 예측값 계산\n","        outputs = model(imgs)\n","        # 손실 계산\n","        loss = criterion(outputs, labels)\n","\n","        # 옵티마이저의 그래디언트 초기화\n","        optimizer.zero_grad()\n","        # 손실을 역전파하여 그래디언트 계산\n","        loss.backward()\n","        # 옵티마이저로 가중치 업데이트\n","        optimizer.step()\n","\n","        # 배치 손실 및 정확도 계산\n","        epoch_loss += loss.item()\n","        _, argmax = torch.max(outputs, 1)\n","        accuracy = (labels == argmax).float().mean()\n","        epoch_accuracy += accuracy.item()\n","\n","        # 100번의 반복마다 손실과 정확도 출력\n","        if (i + 1) % 100 == 0:\n","            print(f'Epoch [{epoch + 1}/{training_epochs}], '\n","                  f'Step[{i + 1}/{len(train_loader)}], '\n","                  f'Loss: {loss.item():.4f}, Accuracy: {accuracy.item() * 100:.2f}%')\n","\n","    # 에포크별 평균 손실 및 정확도 기록\n","    loss_history.append(epoch_loss / len(train_loader))\n","    accuracy_history.append(epoch_accuracy / len(train_loader))\n","\n","# 학습이 끝나면 테스트 데이터로 평가\n","model.eval()\n","with torch.no_grad():\n","    test_loss = 0\n","    test_accuracy = 0\n","    for imgs, labels in test_loader:\n","        imgs, labels = imgs.to(device), labels.to(device)\n","        imgs = imgs.view(-1, 28 * 28)\n","        outputs = model(imgs)\n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","        _, argmax = torch.max(outputs, 1)\n","        accuracy = (labels == argmax).float().mean()\n","        test_accuracy += accuracy.item()\n","    test_loss /= len(test_loader)\n","    test_accuracy /= len(test_loader)\n","    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}